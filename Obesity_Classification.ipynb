{"cells":[{"cell_type":"markdown","metadata":{"id":"q8-FhykA4ARr"},"source":["## **Owner**: Ahmed Tarek Mohamed"]},{"cell_type":"markdown","metadata":{"id":"p63xTmw3veb4"},"source":["# **Data Frame One (Obesity)**"]},{"cell_type":"markdown","metadata":{"id":"Ee3_dgf-vjK4"},"source":["# **1. Import Libraries & Tools**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7E6jP2Y8LDIM"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score, classification_report"]},{"cell_type":"markdown","metadata":{"id":"A0zPd9Yevp2Q"},"source":["**Setting up the environment by importing essential libraries and tool**\n"," * import pandas as pd: This imports the Pandas library, which is widely used for data manipulation and analysis in Python. It is typically used to work with structured data in tabular form.\n","\n"," * from sklearn.model_selection import train_test_split: This imports the train_test_split function from scikit-learn, a machine learning library. It's used for splitting a dataset into training and testing sets.\n","\n"," * from sklearn.preprocessing import StandardScaler, LabelEncoder: This imports the StandardScaler and LabelEncoder classes from scikit-learn. StandardScaler is often used to standardize or scale numerical features, while LabelEncoder is used to convert categorical labels into numeric format.\n","\n"," * from sklearn.linear_model import LogisticRegression: This imports the LogisticRegression class, which is used for logistic regression, a type of linear model commonly used for binary classification problems.\n","\n"," * from sklearn.tree import DecisionTreeClassifier: This imports the DecisionTreeClassifier class, which is used for constructing decision tree models. Decision trees are used for both classification and regression tasks.\n","\n"," * from sklearn.ensemble import RandomForestClassifier: This imports the RandomForestClassifier class, which is an ensemble learning method based on constructing multiple decision trees and combining their outputs. It's often used for classification tasks.\n","\n"," * from sklearn.svm import SVC: This imports the SVC class, which stands for Support Vector Classification. It is used for classification tasks and is a part of the support vector machines (SVM) family.\n","\n"," * from sklearn.neighbors import KNeighborsClassifier: This imports the KNeighborsClassifier class, which is used for k-nearest neighbors classification. It classifies a data point based on the majority class of its k nearest neighbors.\n","\n"," * from sklearn.naive_bayes import GaussianNB: This imports the GaussianNB class, which is used for Naive Bayes classification. It is based on the Bayes' theorem and assumes independence between features.\n","\n"," * from sklearn.metrics import accuracy_score, classification_report: This imports evaluation metrics from scikit-learn. accuracy_score is a common metric for classification problems, and classification_report provides a comprehensive report with precision, recall, and F1-score for each class."]},{"cell_type":"markdown","metadata":{"id":"LV48UNrowL24"},"source":["# **2. Import Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1705847732323,"user":{"displayName":"ahmed tarek","userId":"08412486906813382868"},"user_tz":-480},"id":"RWupG7PgUocO","outputId":"cf18081e-5db9-4433-9b72-7f47c6efd973"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-ef77d8c8-e291-4277-8651-533f17081801\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Height</th>\n","      <th>Weight</th>\n","      <th>family_history_with_overweight</th>\n","      <th>FAVC</th>\n","      <th>FCVC</th>\n","      <th>NCP</th>\n","      <th>CAEC</th>\n","      <th>SMOKE</th>\n","      <th>CH2O</th>\n","      <th>SCC</th>\n","      <th>FAF</th>\n","      <th>TUE</th>\n","      <th>CALC</th>\n","      <th>MTRANS</th>\n","      <th>NObeyesdad</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Female</td>\n","      <td>21.0</td>\n","      <td>1.62</td>\n","      <td>64.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>Sometimes</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>no</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>no</td>\n","      <td>Public_Transportation</td>\n","      <td>Normal_Weight</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Female</td>\n","      <td>21.0</td>\n","      <td>1.52</td>\n","      <td>56.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>Sometimes</td>\n","      <td>yes</td>\n","      <td>3.0</td>\n","      <td>yes</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>Sometimes</td>\n","      <td>Public_Transportation</td>\n","      <td>Normal_Weight</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Male</td>\n","      <td>23.0</td>\n","      <td>1.80</td>\n","      <td>77.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>Sometimes</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>Frequently</td>\n","      <td>Public_Transportation</td>\n","      <td>Normal_Weight</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Male</td>\n","      <td>27.0</td>\n","      <td>1.80</td>\n","      <td>87.0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>Sometimes</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>Frequently</td>\n","      <td>Walking</td>\n","      <td>Overweight_Level_I</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Male</td>\n","      <td>22.0</td>\n","      <td>1.78</td>\n","      <td>89.8</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>Sometimes</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>no</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Sometimes</td>\n","      <td>Public_Transportation</td>\n","      <td>Overweight_Level_II</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef77d8c8-e291-4277-8651-533f17081801')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ef77d8c8-e291-4277-8651-533f17081801 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ef77d8c8-e291-4277-8651-533f17081801');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-fcff5682-36bc-4fe5-8c2b-1e72ce9256b2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fcff5682-36bc-4fe5-8c2b-1e72ce9256b2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-fcff5682-36bc-4fe5-8c2b-1e72ce9256b2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n","0  Female  21.0    1.62    64.0                            yes   no   2.0   \n","1  Female  21.0    1.52    56.0                            yes   no   3.0   \n","2    Male  23.0    1.80    77.0                            yes   no   2.0   \n","3    Male  27.0    1.80    87.0                             no   no   3.0   \n","4    Male  22.0    1.78    89.8                             no   no   2.0   \n","\n","   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n","0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n","1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n","2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n","3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n","4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n","\n","                  MTRANS           NObeyesdad  \n","0  Public_Transportation        Normal_Weight  \n","1  Public_Transportation        Normal_Weight  \n","2  Public_Transportation        Normal_Weight  \n","3                Walking   Overweight_Level_I  \n","4  Public_Transportation  Overweight_Level_II  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Load the dataset\n","data = pd.read_csv('/Datasets/ObesityDataSet.csv')\n","data.head()"]},{"cell_type":"markdown","metadata":{"id":"HVUTfBA-wO8v"},"source":["# **3. Preprocess Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mOagi5GGVoI3"},"outputs":[],"source":["# Encoding categorical variables\n","label_encoders = {}\n","for column in data.select_dtypes(include=['object']).columns:\n","    label_encoders[column] = LabelEncoder()\n","    data[column] = label_encoders[column].fit_transform(data[column])\n","\n","# Splitting the data into features and target\n","X = data.drop('NObeyesdad', axis=1)\n","y = data['NObeyesdad']\n","\n","# Normalizing numerical variables\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Splitting the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"]},{"cell_type":"markdown","metadata":{"id":"-4Cx_iJvxU45"},"source":["* **Encoding Categorical Variables:**\n"," * Iterate over columns with data type 'object.'\n"," * For each column, create a LabelEncoder.\n"," * Fit and transform the column's values into numerical labels.\n"," * Replace the original column with numerical labels.\n","\n","* **Splitting into Features and Target:**\n"," * Create features (X) by excluding the 'NObeyesdad' column.\n"," * Set the target variable (y) to the values in the 'NObeyesdad' column.\n","\n","* **Normalizing Numerical Variables:**\n"," * Use StandardScaler to normalize numerical features in X.\n"," * Standardization removes the mean and scales to unit variance.\n","\n","* **Splitting into Training and Testing Sets:**\n"," * Use train_test_split to split the dataset.\n"," * Allocate 70% for training (X_train, y_train) and 30% for testing (X_test, y_test).\n"," * Set random_state for reproducibility."]},{"cell_type":"markdown","metadata":{"id":"WKGATI53wZZ2"},"source":["# **4. Classification Models**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JAm4sn3FVKoS"},"outputs":[],"source":["# Initializing models\n","models = {\n","    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n","    \"Decision Tree\": DecisionTreeClassifier(),\n","    \"Random Forest\": RandomForestClassifier(),\n","    \"SVM\": SVC(),\n","    \"KNN\": KNeighborsClassifier(),\n","    \"Naive Bayes\": GaussianNB()\n","}"]},{"cell_type":"markdown","metadata":{"id":"R915Cg9DyOi5"},"source":["* **Logistic Regression:**\n"," Logistic Regression is a linear model commonly used for binary classification problems. The max_iter parameter is set to 1000, which represents the maximum number of iterations for the solver to converge.\n","\n","* **Decision Tree:**\n","Decision Tree is a model that makes decisions based on a tree-like model of decisions. It's used for both classification and regression tasks.\n","\n","* **Random Forest:**\n","Random Forest is an ensemble learning method based on constructing multiple decision trees during training and combining their outputs. It's often used for classification tasks.\n","\n","* **SVM (Support Vector Machine):**\n","SVM is a model used for classification tasks. It works by finding the hyperplane that best separates different classes in the feature space.\n","\n","* **K-Nearest Neighbors (KNN):**\n","KNN is a simple and effective algorithm used for classification. It classifies a data point based on the majority class of its k nearest neighbors.\n","\n","* **Naive Bayes:**\n","Naive Bayes is a probabilistic model based on Bayes' theorem. It is often used for classification tasks, assuming independence between features."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":979,"status":"ok","timestamp":1705847733295,"user":{"displayName":"ahmed tarek","userId":"08412486906813382868"},"user_tz":-480},"id":"t1z_tjKBVYvn","outputId":"2ecb6bb2-da4f-4b53-ee44-667658a83361"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: Logistic Regression\n","Accuracy: 0.8596214511041009\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.99      0.89        86\n","           1       0.86      0.60      0.71        93\n","           2       0.94      0.90      0.92       102\n","           3       0.91      0.98      0.94        88\n","           4       1.00      0.99      0.99        98\n","           5       0.74      0.73      0.74        88\n","           6       0.74      0.82      0.78        79\n","\n","    accuracy                           0.86       634\n","   macro avg       0.86      0.86      0.85       634\n","weighted avg       0.86      0.86      0.86       634\n","\n","---------------------------------------------------\n","Model: Decision Tree\n","Accuracy: 0.9085173501577287\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.95      0.92        86\n","           1       0.82      0.78      0.80        93\n","           2       0.97      0.90      0.93       102\n","           3       0.93      0.98      0.96        88\n","           4       1.00      0.99      0.99        98\n","           5       0.85      0.82      0.83        88\n","           6       0.89      0.94      0.91        79\n","\n","    accuracy                           0.91       634\n","   macro avg       0.91      0.91      0.91       634\n","weighted avg       0.91      0.91      0.91       634\n","\n","---------------------------------------------------\n","Model: Random Forest\n","Accuracy: 0.944794952681388\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.94      0.96        86\n","           1       0.81      0.94      0.87        93\n","           2       0.99      0.96      0.98       102\n","           3       0.96      0.99      0.97        88\n","           4       1.00      0.99      0.99        98\n","           5       0.93      0.84      0.88        88\n","           6       0.97      0.95      0.96        79\n","\n","    accuracy                           0.94       634\n","   macro avg       0.95      0.94      0.94       634\n","weighted avg       0.95      0.94      0.95       634\n","\n","---------------------------------------------------\n","Model: SVM\n","Accuracy: 0.8738170347003155\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.93      0.91        86\n","           1       0.70      0.83      0.76        93\n","           2       0.95      0.86      0.90       102\n","           3       0.92      0.98      0.95        88\n","           4       1.00      0.99      0.99        98\n","           5       0.81      0.72      0.76        88\n","           6       0.85      0.80      0.82        79\n","\n","    accuracy                           0.87       634\n","   macro avg       0.88      0.87      0.87       634\n","weighted avg       0.88      0.87      0.87       634\n","\n","---------------------------------------------------\n","Model: KNN\n","Accuracy: 0.805993690851735\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.93      0.80        86\n","           1       0.66      0.45      0.54        93\n","           2       0.81      0.87      0.84       102\n","           3       0.84      0.97      0.90        88\n","           4       0.99      1.00      0.99        98\n","           5       0.84      0.65      0.73        88\n","           6       0.76      0.76      0.76        79\n","\n","    accuracy                           0.81       634\n","   macro avg       0.80      0.80      0.79       634\n","weighted avg       0.80      0.81      0.80       634\n","\n","---------------------------------------------------\n","Model: Naive Bayes\n","Accuracy: 0.6056782334384858\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.81      0.73        86\n","           1       0.56      0.35      0.43        93\n","           2       0.36      0.63      0.46       102\n","           3       0.70      0.89      0.78        88\n","           4       1.00      0.99      0.99        98\n","           5       0.48      0.28      0.36        88\n","           6       0.53      0.22      0.31        79\n","\n","    accuracy                           0.61       634\n","   macro avg       0.61      0.60      0.58       634\n","weighted avg       0.61      0.61      0.59       634\n","\n","---------------------------------------------------\n"]}],"source":["# Training and evaluating models\n","results = {}\n","for name, model in models.items():\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    report = classification_report(y_test, y_pred)\n","    results[name] = {'accuracy': accuracy, 'report': report}\n","\n","# Displaying the results\n","for model_name, metrics in results.items():\n","    print(f\"Model: {model_name}\")\n","    print(f\"Accuracy: {metrics['accuracy']}\")\n","    print(\"Classification Report:\")\n","    print(metrics['report'])\n","    print(\"---------------------------------------------------\")"]},{"cell_type":"markdown","metadata":{"id":"HRGCIGyzy0wa"},"source":["* **Training and Evaluating Models:**\n"," * Iterates through each model in the models dictionary.\n"," * Calls the fit method to train the model using the training data (X_train, y_train).\n"," * Predicts the target variable (y_pred) using the test data (X_test).\n"," * Calculates the accuracy of the predictions using accuracy_score.\n"," * Generates a classification report using classification_report.\n"," * Stores the results (accuracy and report) in the results dictionary, with the model name as the key.\n","\n","* **Displaying the Results:**\n"," * Iterates through the results of each model stored in the results dictionary.\n"," * Prints the model name, accuracy, and the classification report for each model.\n"," * Separates the output with a line of dashes for better readability."]},{"cell_type":"markdown","metadata":{"id":"o52sJOETwnCJ"},"source":["# **Data Frame two (Diabetes)**"]},{"cell_type":"markdown","metadata":{"id":"NbdVvifYwts4"},"source":["# **1. Import Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1705847733295,"user":{"displayName":"ahmed tarek","userId":"08412486906813382868"},"user_tz":-480},"id":"DteoWIELVt3r","outputId":"57d54046-9a6b-40ca-ae40-d4e013f3d75c"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-534db5a1-1c8b-455f-841e-37e80ed4df0e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Diabetes_012</th>\n","      <th>HighBP</th>\n","      <th>HighChol</th>\n","      <th>CholCheck</th>\n","      <th>BMI</th>\n","      <th>Smoker</th>\n","      <th>Stroke</th>\n","      <th>HeartDiseaseorAttack</th>\n","      <th>PhysActivity</th>\n","      <th>Fruits</th>\n","      <th>...</th>\n","      <th>AnyHealthcare</th>\n","      <th>NoDocbcCost</th>\n","      <th>GenHlth</th>\n","      <th>MentHlth</th>\n","      <th>PhysHlth</th>\n","      <th>DiffWalk</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Education</th>\n","      <th>Income</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>40</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>5.0</td>\n","      <td>18.0</td>\n","      <td>15.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>25</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>7.0</td>\n","      <td>6.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>28</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>30.0</td>\n","      <td>30.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>9.0</td>\n","      <td>4.0</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>27</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>3.0</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>24</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>5.0</td>\n","      <td>4.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-534db5a1-1c8b-455f-841e-37e80ed4df0e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-534db5a1-1c8b-455f-841e-37e80ed4df0e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-534db5a1-1c8b-455f-841e-37e80ed4df0e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7c606639-661a-4576-9e6c-3c25715d3cd3\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c606639-661a-4576-9e6c-3c25715d3cd3')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7c606639-661a-4576-9e6c-3c25715d3cd3 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["   Diabetes_012  HighBP  HighChol  CholCheck  BMI  Smoker  Stroke  \\\n","0             0       1         1          1   40     1.0     0.0   \n","1             0       0         0          0   25     1.0     0.0   \n","2             0       1         1          1   28     0.0     0.0   \n","3             0       1         0          1   27     0.0     0.0   \n","4             0       1         1          1   24     0.0     0.0   \n","\n","   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n","0                   0.0           0.0     0.0  ...            1.0   \n","1                   0.0           1.0     0.0  ...            0.0   \n","2                   0.0           0.0     1.0  ...            1.0   \n","3                   0.0           1.0     1.0  ...            1.0   \n","4                   0.0           1.0     1.0  ...            1.0   \n","\n","   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n","0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n","1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n","2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n","3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n","4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n","\n","   Income  \n","0     3.0  \n","1     1.0  \n","2     8.0  \n","3     6.0  \n","4     4.0  \n","\n","[5 rows x 22 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Load the dataset\n","data2 = pd.read_csv('/content/DiabetesDataSet.csv')\n","data2.head()"]},{"cell_type":"markdown","metadata":{"id":"bLCFttUAwzlU"},"source":["# **2. Preprocess Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ygbylwtV6XM"},"outputs":[],"source":["# Encoding categorical variables\n","label_encoders2 = {}\n","for column in data2.select_dtypes(include=['object']).columns:\n","    label_encoders2[column] = LabelEncoder()\n","    data2[column] = label_encoders2[column].fit_transform(data2[column])\n","\n","# Splitting the data into features and target\n","XX = data2.drop('Diabetes_012', axis=1)\n","yy = data2['Diabetes_012']\n","\n","# Normalizing numerical variables\n","scaler2 = StandardScaler()\n","XX = scaler2.fit_transform(XX)\n","\n","# Selecting the first 2111 rows\n","XX_selected = XX[:2111]\n","yy_selected = yy[:2111]\n","\n","# Splitting the selected dataset into training and testing sets\n","XX_train, XX_test, yy_train, yy_test = train_test_split(XX_selected, yy_selected, test_size=0.3, random_state=42)\n"]},{"cell_type":"markdown","metadata":{"id":"04bKfFWnzP9L"},"source":["* **Encoding Categorical Variables:**\n"," * Similar to the previous code, this loop iterates over each column in data2 with data type 'object.'\n"," * Creates a LabelEncoder for each column.\n"," * Fits and transforms the column's values into numerical labels.\n"," * Replaces the original column with these numerical labels.\n"," * The label_encoders2 dictionary is used to store the LabelEncoder objects for potential later use.\n","\n","* Splitting into Features and Target:\n"," * Creates features (XX) by excluding the 'Diabetes_012' column.\n"," * Sets the target variable (yy) to the values in the 'Diabetes_012' column.\n","\n","* Normalizing Numerical Variables: Normalizes numerical features in XX using the StandardScaler.\n","\n","* Selecting Subset of Data: Selects the first 2111 rows of the normalized data (XX and yy). It seems like a subset of the original dataset.\n","\n","* Splitting into Training and Testing Sets:\n"," * Splits the selected dataset into training and testing sets using the train_test_split function.\n"," * Allocates 70% for training (XX_train, yy_train) and 30% for testing (XX_test, yy_test).\n"," * random_state is set for reproducibility."]},{"cell_type":"markdown","metadata":{"id":"gQVzA56fw7KL"},"source":["# **3. Classification Models**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-f9xf6UioJx"},"outputs":[],"source":["# Initializing models\n","models2 = {\n","    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n","    \"Decision Tree\": DecisionTreeClassifier(),\n","    \"Random Forest\": RandomForestClassifier(),\n","    \"SVM\": SVC(),\n","    \"KNN\": KNeighborsClassifier(),\n","    \"Naive Bayes\": GaussianNB()\n","}"]},{"cell_type":"markdown","metadata":{"id":"r40jobZ00ONk"},"source":["* **Logistic Regression:**\n"," Logistic Regression is a linear model commonly used for binary classification problems. The max_iter parameter is set to 1000, which represents the maximum number of iterations for the solver to converge.\n","\n","* **Decision Tree:**\n","Decision Tree is a model that makes decisions based on a tree-like model of decisions. It's used for both classification and regression tasks.\n","\n","* **Random Forest:**\n","Random Forest is an ensemble learning method based on constructing multiple decision trees during training and combining their outputs. It's often used for classification tasks.\n","\n","* **SVM (Support Vector Machine):**\n","SVM is a model used for classification tasks. It works by finding the hyperplane that best separates different classes in the feature space.\n","\n","* **K-Nearest Neighbors (KNN):**\n","KNN is a simple and effective algorithm used for classification. It classifies a data point based on the majority class of its k nearest neighbors.\n","\n","* **Naive Bayes:**\n","Naive Bayes is a probabilistic model based on Bayes' theorem. It is often used for classification tasks, assuming independence between features."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1997,"status":"ok","timestamp":1705847851918,"user":{"displayName":"ahmed tarek","userId":"08412486906813382868"},"user_tz":-480},"id":"HEsOIQGXiprq","outputId":"79d7308f-00f6-40ec-f669-429967f4bc75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: Logistic Regression\n","Accuracy: 0.7523659305993691\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.94      0.85       477\n","           1       1.00      0.00      0.00         9\n","           2       0.49      0.20      0.29       148\n","\n","    accuracy                           0.75       634\n","   macro avg       0.76      0.38      0.38       634\n","weighted avg       0.72      0.75      0.71       634\n","\n","---------------------------------------------------\n","Model: Decision Tree\n","Accuracy: 0.6451104100946372\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.76      0.77       477\n","           1       0.00      0.00      0.00         9\n","           2       0.30      0.31      0.31       148\n","\n","    accuracy                           0.65       634\n","   macro avg       0.36      0.36      0.36       634\n","weighted avg       0.66      0.65      0.65       634\n","\n","---------------------------------------------------\n","Model: Random Forest\n","Accuracy: 0.7476340694006309\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.95      0.85       477\n","           1       1.00      0.00      0.00         9\n","           2       0.46      0.15      0.22       148\n","\n","    accuracy                           0.75       634\n","   macro avg       0.74      0.37      0.36       634\n","weighted avg       0.70      0.75      0.69       634\n","\n","---------------------------------------------------\n","Model: SVM\n","Accuracy: 0.7476340694006309\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.96      0.85       477\n","           1       1.00      0.00      0.00         9\n","           2       0.45      0.09      0.16       148\n","\n","    accuracy                           0.75       634\n","   macro avg       0.74      0.35      0.34       634\n","weighted avg       0.69      0.75      0.68       634\n","\n","---------------------------------------------------\n","Model: KNN\n","Accuracy: 0.7318611987381703\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.91      0.84       477\n","           1       0.00      0.00      0.00         9\n","           2       0.42      0.22      0.28       148\n","\n","    accuracy                           0.73       634\n","   macro avg       0.40      0.37      0.37       634\n","weighted avg       0.68      0.73      0.70       634\n","\n","---------------------------------------------------\n","Model: Naive Bayes\n","Accuracy: 0.06782334384858044\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.07      0.14       477\n","           1       0.01      0.89      0.03         9\n","           2       1.00      0.00      0.00       148\n","\n","    accuracy                           0.07       634\n","   macro avg       0.63      0.32      0.05       634\n","weighted avg       0.89      0.07      0.10       634\n","\n","---------------------------------------------------\n"]}],"source":["# Training and evaluating models\n","results2 = {}\n","for name, model in models2.items():\n","    model.fit(XX_train, yy_train)\n","    yy_pred = model.predict(XX_test)\n","    accuracy2 = accuracy_score(yy_test, yy_pred)\n","    report2 = classification_report(yy_test, yy_pred, zero_division=1)\n","    results2[name] = {'accuracy': accuracy2, 'report': report2}\n","\n","# Displaying the results\n","for model_name, metrics in results2.items():\n","    print(f\"Model: {model_name}\")\n","    print(f\"Accuracy: {metrics['accuracy']}\")\n","    print(\"Classification Report:\")\n","    print(metrics['report'])\n","    print(\"---------------------------------------------------\")\n"]},{"cell_type":"markdown","metadata":{"id":"IvNQToVv0chn"},"source":["* **Training and Evaluating Models:**\n"," * Iterates through each model in the models2 dictionary (presumably similar to the previous models but applied to the new dataset).\n"," * Calls the fit method to train the model using the training data (XX_train, yy_train).\n"," * Predicts the target variable (yy_pred) using the test data (XX_test).\n"," * Calculates the accuracy of the predictions using accuracy_score.\n"," * Generates a classification report using classification_report.\n"," * Stores the results (accuracy and report) in the results2 dictionary, with the model name as the key.\n","\n","* **Displaying the Results:**\n"," * Iterates through the results of each model stored in the results2 dictionary.\n"," * Prints the model name, accuracy, and the classification report for each model.\n"," * Separates the output with a line of dashes for better readability."]},{"cell_type":"markdown","metadata":{"id":"lR5WLbGTdcX2"},"source":["# **Final Summary**"]},{"cell_type":"markdown","metadata":{"id":"Gpa9eXxqdfut"},"source":["* **Summary:**\n","  * Logistic Regression achieved an accuracy of 0.86, with varying precision, recall, and f1-scores across different classes. It performed well in some classes (e.g., class 0 and class 4) but less so in others (e.g., class 1 and class 5).\n","  * Decision Tree achieved an accuracy of 0.91, demonstrating good performance with high precision, recall, and f1-scores in most classes. It outperformed Logistic Regression in terms of accuracy and overall class-wise metrics.\n","  * Random Forest outperformed both Logistic Regression and Decision Tree with an accuracy of 0.94. It showed high precision, recall, and f1-scores across all classes, indicating strong overall performance.\n","  * SVM achieved an accuracy of 0.87, with relatively balanced precision, recall, and f1-scores. It performed consistently across different classes, demonstrating robustness.\n","  * KNN had an accuracy of 0.81, displaying decent performance with varying precision, recall, and f1-scores across classes. It was less accurate compared to Decision Tree, Random Forest, and SVM.\n","  * Naive Bayes had the lowest accuracy of 0.61, with lower precision, recall, and f1-scores across most classes. It showed limitations in handling the complexity of the data.\n","\n","* **Conclusion:**\n","  * In this comparison, Random Forest stands out as the top-performing model with the highest accuracy (0.94) and strong class-wise metrics. Decision Tree also performed well, achieving an accuracy of 0.91. Logistic Regression, SVM, and KNN demonstrated moderate performance, with SVM being the most robust among them. Naive Bayes performed the least effectively with the lowest accuracy of 0.61. The choice of the best model depends on the specific requirements and characteristics of the dataset, but Random Forest seems to be a strong candidate for this classification task."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMKREM7wz4MDk1GQr7OLS83","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
